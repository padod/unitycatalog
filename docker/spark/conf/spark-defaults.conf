# ============================================
# Delta Lake Configuration
# ============================================
spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension
spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog

# ============================================
# Unity Catalog Configuration
# ============================================
spark.sql.catalog.unity=io.unitycatalog.spark.UCSingleCatalog
spark.sql.catalog.unity.uri=http://unity-catalog:8080
spark.sql.catalog.unity.token=
spark.sql.defaultCatalog=unity

# ============================================
# S3A FileSystem Implementation
# ============================================
# NOTE: Credentials are NOT configured here!
# Unity Catalog server vends temporary credentials to Spark
# based on server.properties configuration.
# Only the filesystem implementation is specified here.
spark.hadoop.fs.s3.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem

# ============================================
# Delta Lake LogStore Configuration for S3
# ============================================
# Use S3SingleDriverLogStore instead of default S3DynamoDBLogStore
# to avoid STS calls for third-party S3 providers like MinIO
spark.delta.logStore.s3a.impl=org.apache.spark.sql.delta.storage.S3SingleDriverLogStore

# ============================================
# Performance Settings
# ============================================
spark.sql.adaptive.enabled=true
spark.sql.adaptive.coalescePartitions.enabled=true
spark.serializer=org.apache.spark.serializer.KryoSerializer